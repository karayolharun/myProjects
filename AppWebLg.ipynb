{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppWebLg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMNPrVgzpidW",
        "colab_type": "code",
        "outputId": "b353f7f1-306f-4f91-ac1a-9d4e6d30a0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=3930a5dae330d96cd4fa996d6243fd240ee5e883cc84753dea4b7064e5d0ee3c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4h86vvfa/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIZouoibcn-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#((vehicle seat)) ((folding mechanism)) (lock) before:publication:20140624\n",
        "\n",
        "#https://patents.google.com/?q=(vehicle+seat)&q=(folding+mechanism)&q=lock&before=publication:20140624\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dac4Uu2BbtTX",
        "colab_type": "code",
        "outputId": "c64325e4-3732-4e43-9966-5d616d990df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#------------------------SAVES OUTPUT TO TEXT FILE---------------------------\n",
        "# URLs \n",
        "# REFERENCES\n",
        "# NOUN-PHRASES\n",
        "# QUERY\n",
        "\n",
        "\n",
        "#import py_compile\n",
        "\n",
        "\n",
        "#script = \"/content/drive/My Drive/kodlar/kod.py\"\n",
        "#py_compile.compile(script)\n",
        "import os\n",
        "import shutil\n",
        "from os import path\n",
        "\n",
        "import time\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "\n",
        "f = open('/content/drive/My Drive/MYOUTPUT.txt', 'a')\n",
        "choice_text = input(\"Description or Claim ? : \")\n",
        "if choice_text.lower()==\"d\":\n",
        "  #os.rename('/content/drive/My Drive/MYOUTPUT.txt','/content/drive/My Drive/MYOUTPUT-D.txt')\n",
        "  #f.close() \n",
        "  #f = open('/content/drive/My Drive/MYOUTPUT-D.txt', 'a')\n",
        "  print(\"MYOUTPUT-D\\nINPUT IS DESCRIPTION TEXT\\n\",file=f)\n",
        "  print(\"INPUT IS DESCRIPTION TEXT\\n\")\n",
        "else: \n",
        "  #os.rename('/content/drive/My Drive/MYOUTPUT.txt','/content/drive/My Drive/MYOUTPUT-C.txt') \n",
        "  #f.close() \n",
        "  #f = open('/content/drive/My Drive/MYOUTPUT-C.txt', 'a')\n",
        "  print(\"MYOUTPUT-C\\nINPUT IS CLAIM TEXT\\n\",file=f)\n",
        "  print(\"INPUT IS CLAIM TEXT\\n\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "while True:\n",
        "  oldest_date = input(\"For prior art search insert the priority or filing date in format:yyyymmdd  \")\n",
        " \n",
        "  if int(oldest_date[4:6])>12 or int(oldest_date[6:])>31:\n",
        "    print(\"Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "  \n",
        "  elif (oldest_date[4:6]=='00') or (oldest_date[6:]=='00'):\n",
        "    print(\"Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "      \n",
        "  elif oldest_date[4:6]=='02' and oldest_date[6:]=='30':\n",
        "    print(\"February cannot have 30 days. Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "  \n",
        "  elif oldest_date[4:6]=='02' and oldest_date[6:]=='31':\n",
        "    print(\"February cannot have 31 days. Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "\n",
        "  elif int(oldest_date[:4])%4 != 0 and oldest_date[4:6]=='02' and oldest_date[6:] == '29':\n",
        "    print(\"This is not a leap year. Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "\n",
        "  \n",
        "  elif oldest_date.isnumeric and len(oldest_date)==8:\n",
        "    if int(oldest_date[4:6])<13:\n",
        "      if int(oldest_date[6:])<32:\n",
        "        break  \n",
        "  \n",
        "  else:\n",
        "    print(\"Please enter a valid date in format: yyyymmdd  \")\n",
        "    continue\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "if (choice_text.lower()==\"d\"):\n",
        "  words = input(\"Insert description text here:  \")\n",
        "else:\n",
        "  words = input(\"Insert claim text here:  \")\n",
        "\n",
        "\n",
        "\n",
        "doc = nlp(words)\n",
        "#-------------------------------------------------\n",
        "f = open('/content/drive/My Drive/MYOUTPUT.txt', 'a')\n",
        "\n",
        "#IPC SENTENCE BULMA İŞİ\n",
        "try:\n",
        "  ipc_sent = list()\n",
        "  for sent in doc.sents:\n",
        "    for token in sent:\n",
        "      if (token.text.startswith(\"invent\") or token.text.startswith(\"applicat\")) and token.pos_ == 'NOUN':\n",
        "        if doc[token.i+1].text.startswith(\"relat\") or doc[token.i+2].text.startswith(\"relat\")or doc[token.i+1].text.startswith(\"about\") or doc[token.i+2].text.startswith(\"about\") or doc[token.i+1].text.startswith(\"concern\") or doc[token.i+2].text.startswith(\"concern\"):\n",
        "          print(\"\\nIPC sentence:  \",sent,\"\\n\") #sonra silinebilir\n",
        "          ipc_sent.append(sent)\n",
        "          print(\"ipc_sent listesi  :\",sent,\"\\n\") #sonra silinebilir\n",
        "except:\n",
        "  print(\"\\n NO IPC SENTENCE FOUND \\n\")\n",
        "  print(\"\\n NO IPC SENTENCE FOUND \\n\",file=f)\n",
        "\n",
        "#ipc_sent span listesi*\n",
        "\n",
        "if (len(ipc_sent)>0):\n",
        "  doc_ipc_sent = nlp(str(ipc_sent[0]))\n",
        "  print (\"doc_ipc_sent:  \",doc_ipc_sent)\n",
        "else:\n",
        "  print(\"\\n NO IPC SENTENCE FOUND \\n\")\n",
        "  print(\"\\n NO IPC SENTENCE FOUND \\n\",file =f)   \n",
        "\n",
        "ipc_sent_span = doc_ipc_sent\n",
        "for token in doc_ipc_sent:\n",
        "  if token.text.startswith(\"concern\") or token.text.startswith(\"relat\") or token.text.startswith(\"about\"):\n",
        "    ipc_sent_span = doc_ipc_sent[token.i+1:]\n",
        "    break\n",
        "\n",
        "\n",
        "ipc_sent_noun_list = list()\n",
        "for token in ipc_sent_span:\n",
        "  if (token.pos_ == 'ADJ') or (token.pos_ == 'NOUN') or (token.tag_ == 'VBG'):\n",
        "    if  token.text.endswith(\"s\")==True and len(token.text)>3: #ex: \"keys\" sonundaki 's' atılır#\n",
        "      ipc_sent_noun_list.append(str(token)[:-1])\n",
        "    else:\n",
        "      ipc_sent_noun_list.append(str(token))\n",
        "\n",
        "        \n",
        "#ipc_sent_noun_list elemanları string#\n",
        "\n",
        "ipc_sent_noun_set = set(ipc_sent_noun_list)\n",
        "\n",
        "ipc_sent_noun_unique_list = list(ipc_sent_noun_set)\n",
        "\n",
        "print (\"\\n IPC NOUN SET LIST: \",ipc_sent_noun_unique_list)\n",
        "print (\"\\n IPC NOUN SET LIST: \",ipc_sent_noun_unique_list, file=f)\n",
        "\n",
        "#https://patents.google.com/?q=(vehicle+seat)&q=(folding+mechanism)&q=lock&before=publication:20140624\n",
        "ipc_url_noun_addition_string = \"\"\n",
        "if len(ipc_sent_noun_unique_list)>0:\n",
        "  for i in range(len(ipc_sent_noun_unique_list)):\n",
        "    if i==0:\n",
        "      ipc_url_noun_addition_string += \"?q=(\"+ipc_sent_noun_unique_list[i]+\")\"\n",
        "    else:\n",
        "      ipc_url_noun_addition_string += \"&q=(\"+ipc_sent_noun_unique_list[i]+\")\"\n",
        "  ipc_noun_search_url = \"https://patents.google.com/\"+ipc_url_noun_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"    #IPC SEARCH URL PRODUCED\n",
        "else:\n",
        "  print(\"\\nNO IPC NOUN SEARCH URL PRODUCED\\n\")\n",
        "  print(\"\\nNO IPC NOUN SEARCH URL PRODUCED\\n\",file=f)\n",
        "\n",
        "\n",
        "\n",
        "#liste_chunk_ipc , ipc noun-chunk string listesi#\n",
        "liste_chunk_ipc=[]\n",
        "for chunk in ipc_sent_span.noun_chunks:\n",
        "    if chunk[0].is_stop == True or chunk[0].text == \"-\" or chunk[0].is_punct == True or chunk[0].pos_ == 'NUM':\n",
        "      if chunk.text.endswith(\"s\"):\n",
        "        liste_chunk_ipc.append(chunk[1:].text.rstrip(\"s\"))\n",
        "      else:\n",
        "        liste_chunk_ipc.append(chunk[1:].text)\n",
        "    else:\n",
        "      if chunk.text.endswith(\"s\"):\n",
        "        liste_chunk_ipc.append(chunk.text.rstrip(\"s\"))\n",
        "      else:\n",
        "        liste_chunk_ipc.append(chunk.text)\n",
        "      \n",
        "ipc_chunk_set = set(liste_chunk_ipc)\n",
        "\n",
        "ipc_sent_chunk_unique_list = list(ipc_chunk_set)\n",
        "\n",
        "print (\"\\n IPC CHUNK SET LIST: \",ipc_sent_chunk_unique_list)\n",
        "print (\"\\n IPC CHUNK SET LIST: \",ipc_sent_chunk_unique_list, file=f)\n",
        "  \n",
        "  \n",
        "ipc_url_chunk_addition_string = \"\"\n",
        "if len(ipc_sent_chunk_unique_list)>0:\n",
        "  for i in range(len(ipc_sent_chunk_unique_list)):\n",
        "    if i==0:\n",
        "      ipc_url_chunk_addition_string += \"?q=(\"+ipc_sent_chunk_unique_list[i].replace(' ','+')+\")\"\n",
        "    else:\n",
        "      ipc_url_chunk_addition_string += \"&q=(\"+ipc_sent_chunk_unique_list[i].replace(' ','+')+\")\"\n",
        "  ipc_chunk_search_url = \"https://patents.google.com/\"+ipc_url_chunk_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"    #IPC SEARCH URL PRODUCED\n",
        "else:\n",
        "  print(\"\\nNO IPC CHUNK SEARCH URL PRODUCED\\n\")\n",
        "  print(\"\\nNO IPC CHUNK SEARCH URL PRODUCED\\n\",file=f)\n",
        "\n",
        "\n",
        "f.close()\n",
        "\n",
        "#----------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "#for ent in doc.ents:\n",
        "#  print(\"ents: \", ent.text, \" \", ent.label_)\n",
        "\n",
        "#nlp.tokenizer.add_special_case('-', [{ORTH: '-', POS:ADP}])\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "\n",
        "#pattern 00,01,10,11 : referanslar için (ör: a chassis, the chassis, vehicle chassis)\n",
        "pattern00 = [{'POS': 'DET', 'OP': '+'},{'POS':'NOUN'},{'LIKE_NUM': True,'IS_DIGIT': True}]\n",
        "pattern01 = [{'POS':'NOUN'},{'POS':'NOUN'},{'LIKE_NUM': True,'IS_DIGIT': True}]\n",
        "pattern02 = [{'POS':'ADJ'},{'POS':'NOUN'},{'LIKE_NUM': True,'IS_DIGIT': True}]\n",
        "pattern03 = [{'LIKE_NUM': True,'IS_DIGIT': False}, {'POS':'NOUN'},{'LIKE_NUM': True,'IS_DIGIT': True}]\n",
        "pattern10 = [{'POS': 'DET', 'OP': '+'},{'POS':'NOUN'},{'TEXT':'('},{'LIKE_NUM': True,'IS_DIGIT': True},{'TEXT':')'}]\n",
        "pattern11 = [{'POS':'NOUN'},{'POS':'NOUN'},{'TEXT':'('},{'LIKE_NUM': True,'IS_DIGIT': True},{'TEXT':')'}]\n",
        "pattern12 = [{'POS':'ADJ'},{'POS':'NOUN'},{'TEXT':'('},{'LIKE_NUM': True,'IS_DIGIT': True},{'TEXT':')'}]\n",
        "pattern13 = [{'LIKE_NUM': True,'IS_DIGIT': False}, {'POS':'NOUN'},{'TEXT':'('},{'LIKE_NUM': True,'IS_DIGIT': True},{'TEXT':')'}]\n",
        "\n",
        "#pattern 2,3,4 : noun ve noun_phrase için sonrasında frekans belirlenerek SEARCH query keyword belirlemede kullanılıyor\n",
        "\n",
        "pattern2 = [{'LIKE_NUM': True,'IS_DIGIT': False}, {'POS':'NOUN'}]\n",
        "pattern3 = [{'POS':'NOUN'},{'POS':'NOUN'}]\n",
        "#pattern4 = [{'POS':'ADJ'},{'POS':'NOUN'}]\n",
        "\n",
        "matcher.add('REFERENCE',None,pattern00,pattern01,pattern02,pattern03,pattern10,pattern11,pattern12,pattern13)\n",
        "found_matches = matcher(doc)\n",
        "\n",
        "f = open('/content/drive/My Drive/MYOUTPUT.txt', 'a')\n",
        "\n",
        "print(\"\\nPOSSIBLE REFERENCES : \\n\",file=f)\n",
        "for match_id, start, end in found_matches:\n",
        "  string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "  span = doc[start:end]                    # get the matched span\n",
        "  print(match_id, string_id, start, end, span.text,file=f)\n",
        "\n",
        "print('\\n',file=f)\n",
        "\n",
        "\n",
        "if len(found_matches)==0:\n",
        "  print(\"NO POSSIBLE REFERENCE found with given format\\n\",file=f)\n",
        "  print(\"NO POSSIBLE REFERENCE found with given format\\n\")\n",
        "\n",
        "\n",
        "referenceList = [doc[start:end].text for match_id, start, end in found_matches]\n",
        "referenceList_freq = Counter(referenceList)\n",
        "common_words = referenceList_freq.most_common(40)\n",
        "print(\"\\nPOSSIBLE REFERENCES (reference_phrase,freq): \", common_words,\"\\n\", file=f)\n",
        "\n",
        "print(\"SORTED POSSIBLE REFERENCES REGARDING FREQUENCY IN DESCENDING ORDER: \\n\",file=f)\n",
        "print(\"SORTED POSSIBLE REFERENCES REGARDING FREQUENCY IN DESCENDING ORDER: \\n\")\n",
        "\n",
        "\n",
        "sorted_reference_list = [word for (word, freq) in common_words]\n",
        "for i in range(0,len(sorted_reference_list)):\n",
        "  print(str(i+1)+\")-  \"+sorted_reference_list[i],file=f)\n",
        "  print(str(i+1)+\")-  \"+sorted_reference_list[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "matcher.remove('REFERENCE')\n",
        "matcher.add('NOUN_PHRASE',None,pattern2,pattern3)\n",
        "found_matches = matcher(doc)\n",
        "print(\"\\nPOSSIBLE NOUN PHRASES:\\n\", file=f)\n",
        "for match_id, start, end in found_matches:\n",
        "  string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "  span = doc[start:end]                    # get the matched span\n",
        "  print(match_id, string_id, start, end, span.text,file=f)\n",
        "    \n",
        "    \n",
        "startDocText = [doc[start:end].text for match_id, start, end in found_matches]\n",
        "\n",
        "\n",
        "unexpected_element=[]\n",
        "try:\n",
        "  for i in range(0,len(startDocText)):\n",
        "    if \"-\" in startDocText[i]:\n",
        "      #print(\"unexpected element = \")\n",
        "      unexpected_element.append(startDocText[i])\n",
        "except IndexError:\n",
        "  print(\"ERROR:index out of range\",file=f)\n",
        "\n",
        "print(\"List for unexpected element:\",unexpected_element,file=f)\n",
        "\n",
        "startDocText = [x for x in startDocText if x not in unexpected_element]\n",
        "\n",
        "\n",
        "print(\"\\nCRITICAL IPC KEYWORDS (comprising system,arrangement,product,device,method etc.):\\n\",file=f)\n",
        "print(\"\\nCRITICAL IPC KEYWORDS (comprising system,arrangement,product,device,method etc.):\\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "    #if (startDocText[i][0] != '-' or startDocText[i][-1] != '-'):\n",
        "  for i in range(len(startDocText)):\n",
        "    if (startDocText[i].split()[1].lower()== \"system\" or\n",
        "        startDocText[i].split()[1].lower()==\"arrangement\" or\n",
        "        startDocText[i].split()[1].lower()==\"arangement\" or startDocText[i].split()[1].lower()==\"apparatus\" or\n",
        "        startDocText[i].split()[1].lower()==\"aparatus\" or startDocText[i].split()[1].lower()==\"device\" or\n",
        "        startDocText[i].split()[1].lower()==\"devices\" or\n",
        "        startDocText[i].split()[1].lower()==\"method\" or startDocText[i].split()[1].lower()==\"product\" or \n",
        "        startDocText[i].split()[1].lower()==\"production\" or startDocText[i].split()[1].lower()==\"assembly\" or\n",
        "        startDocText[i].split()[1].lower()==\"asembly\") :\n",
        "      print(startDocText[i],file=f)\n",
        "      print(startDocText[i])\n",
        "      #critical_firstword=startDocText[i]\n",
        "\n",
        "except: \n",
        "  print(\"AN EXCEPTION OCCURED. UNEXPECTED CHARACTER-INDEX ERROR\\n\",file=f)\n",
        "\n",
        "  \n",
        "startDocText_freq = Counter(startDocText)\n",
        "common_words = startDocText_freq.most_common(40)\n",
        "print(\"\\nIPC KEYWORDS (noun_phrase,freq): \", common_words,\"\\n\",file=f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "#((vehicle seat)) ((folding mechanism)) (lock) before:publication:20140624\n",
        "\n",
        "#https://patents.google.com/?q=(vehicle+seat)&q=(folding+mechanism)&q=lock&before=publication:20140624\n",
        "#*************** common_words liste lengthi 2'den küçükse \"list index out of range\" hatası veriyor. Dolayısıyla for ile len(list) şeklinde sınırlandırmak doğru olabilir\n",
        "print(\"\\nSORTED IPC KEYWORDS QUERY FORMAT REGARDING FREQUENCY IN DESCENDING ORDER:\\n\",file=f)\n",
        "print(\"\\nSORTED IPC KEYWORDS QUERY FORMAT REGARDING FREQUENCY IN DESCENDING ORDER:\\n\")\n",
        "\n",
        "\n",
        "query_words=[]\n",
        "try:\n",
        "  for i in range(0,len(common_words)):\n",
        "    #print(startDocText[i][0],startDocText[i][-1])\n",
        "    #if (startDocText[i][0] != '-' or startDocText[i][-1] != '-'):\n",
        "    phrase_firstword = common_words[i][0].split()[0].lower()\n",
        "    phrase_secondword = common_words[i][0].split()[1].lower()\n",
        "    if (phrase_secondword[-1]==\"s\"):\n",
        "      phrase_secondword = common_words[i][0].split()[1][:-1].lower()\n",
        "    query_word = phrase_firstword+\"_\"+phrase_secondword+\"+\"\n",
        "    query_words.append(query_word)\n",
        "    print(str(i+1)+\")-  \"+query_word,file=f)\n",
        "    print(str(i+1)+\")-  \"+query_word)\n",
        "\n",
        "    \n",
        "except:\n",
        "  print('ERROR - UNEXPECTED CHARACTER-INDEX ERROR\\n',file=f)\n",
        "\n",
        "\n",
        "unique_keyword_list = [word for (word, freq) in common_words if freq is 1]\n",
        "print(\"\\nUNIQUE KEYWORDS (freq=1): \\n\",file=f)\n",
        "print(\"\\nUNIQUE KEYWORDS (freq=1): \\n\")\n",
        "\n",
        "if (len(unique_keyword_list) ==0):\n",
        "  print(\"NO UNIQUE KEYWORDS FOUND\",file=f)\n",
        "  print(\"NO UNIQUE KEYWORDS FOUND\")\n",
        "\n",
        "else:\n",
        "  for i in range(len(unique_keyword_list)):\n",
        "    print(unique_keyword_list[i],file=f)\n",
        "    print(unique_keyword_list[i])\n",
        "\n",
        "\n",
        "\n",
        "#print(\"\\nCRITICAL IPC KEYWORDS (comprising system,arrangement,product,device,method etc.):\\n\")\n",
        "#for i in range(0,len(critical_keyword_list)):\n",
        " # if (critical_keyword_list[i].split()[1].lower()== \"system\" or\n",
        "  #    critical_keyword_list[i].split()[1].lower()==\"arrangement\" or\n",
        "   #   critical_keyword_list[i].split()[1].lower()==\"arangement\" or critical_keyword_list[i].split()[1].lower()==\"apparatus\" or\n",
        "    #  critical_keyword_list[i].split()[1].lower()==\"aparatus\" or critical_keyword_list[i].split()[1].lower()==\"device\" or\n",
        "     # critical_keyword_list[i].split()[1].lower()==\"method\" or critical_keyword_list[i].split()[1].lower()==\"product\" or \n",
        "      #critical_keyword_list[i].split()[1].lower()==\"production\" or critical_keyword_list[i].split()[1].lower()==\"assembly\" or\n",
        "      #critical_keyword_list[i].split()[1].lower()==\"asembly\"):\n",
        "    #print(critical_keyword_list[i])\n",
        " \n",
        "  \n",
        "print(\"\\nPROBABLE PATENW QUERY FOR IPC OR SIMILAR DOCUMENTS : \\n\",file=f)\n",
        "print(\"\\nPROBABLE PATENW QUERY FOR IPC OR SIMILAR DOCUMENTS : \\n\")\n",
        "\n",
        "patenw_query = \" \"\n",
        "if (len(query_words) > 3):\n",
        "  for i in range(0,3):\n",
        "    patenw_query += query_words[i]+\",\"\n",
        "  print(\"and\"+patenw_query[:-1],file=f)\n",
        "  print(\"and\"+patenw_query[:-1])\n",
        "  url = \"https://patents.google.com/?q=({})&q=({})&q=({})&before=publication:{}\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1],query_words[2].replace('_','+')[:-1],oldest_date)+\"&clustered=true\"\n",
        "  print(\"\\nFREQUENCY SEARCH URL: \",url)\n",
        "  print(\"\\nFREQUENCY SEARCH URL: \",url,file=f)\n",
        "  compound_noun_url = \"https://patents.google.com/?q=({})&q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1],query_words[2].replace('_','+')[:-1])+ipc_url_noun_addition_string.replace('?','&')+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "  print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url)   \n",
        "  print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url,file=f)  \n",
        "  compound_chunk_url = \"https://patents.google.com/?q=({})&q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1],query_words[2].replace('_','+')[:-1])+ipc_url_chunk_addition_string.replace('?','&')+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "  print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url)   \n",
        "  print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url,file=f)  \n",
        "\n",
        "#ipc_search_url = \"https://patents.google.com/\"+ipc_url_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "\n",
        " \n",
        "elif (len(query_words) > 0):\n",
        "  for i in range(0,len(query_words)):\n",
        "    patenw_query += query_words[i]+\",\"\n",
        "  print(\"and\"+patenw_query[:-1],file=f)\n",
        "  print(\"and\"+patenw_query[:-1])\n",
        "  if (len(query_words) == 1):\n",
        "    url = \"https://patents.google.com/?q=({})&before=publication:{}\".format(query_words[0].replace('_','+')[:-1],oldest_date)+\"&clustered=true\"\n",
        "    print(\"\\nFREQUENCY SEARCH URL: \",url)\n",
        "    print(\"\\nFREQUENCY SEARCH URL: \",url,file=f)\n",
        "    compound_noun_url = \"https://patents.google.com/?q=({})&q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1])+ipc_url_noun_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "    print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url)   \n",
        "    print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url,file=f)   \n",
        "    compound_chunk_url = \"https://patents.google.com/?q=({})&q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1])+ipc_url_chunk_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "    print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url)   \n",
        "    print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url,file=f)  \n",
        "\n",
        "  elif (len(query_words) == 2):\n",
        "    url = \"https://patents.google.com/?q=({})&q=({})&before=publication:{}\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1],oldest_date)+\"&clustered=true\"\n",
        "    print(\"\\nFREQUENCY SEARCH URL: \",url)\n",
        "    print(\"\\nFREQUENCY SEARCH URL: \",url,file=f)\n",
        "    compound_noun_url = \"https://patents.google.com/?q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1])+ipc_url_noun_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "    print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url)   \n",
        "    print(\"\\nCOMPOUND NOUN SEARCH URL: \",compound_noun_url,file=f)     \n",
        "    compound_chunk_url = \"https://patents.google.com/?q=({})&q=({})\".format(query_words[0].replace('_','+')[:-1],query_words[1].replace('_','+')[:-1])+ipc_url_chunk_addition_string+\"&before=publication:\"+oldest_date+\"&clustered=true\"\n",
        "    print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url)   \n",
        "    print(\"\\nCOMPOUND CHUNK SEARCH URL: \",compound_chunk_url,file=f)    \n",
        "\n",
        "\n",
        "else: \n",
        "  print(\"\"\"NO NOUN PHRASE FOUND... NO RESULTS FOR QUERY !\"\"\",file=f)\n",
        "  print(\"\\nNO FREQUENCY SEARCH URL\\n\",file=f)\n",
        "  print(\"\\nNO COMPOUND SEARCH URL ONLY IPC SEARCH URL PRODUCED\\n\",file=f)\n",
        "\n",
        "  print(\"\"\"NO NOUN PHRASE FOUND... NO RESULTS FOR QUERY !\"\"\")\n",
        "  print(\"\\nNO FREQUENCY SEARCH URL\\n\")\n",
        "  print(\"\\nNO COMPOUND SEARCH URL ONLY IPC SEARCH URL PRODUCED\\n\")\n",
        "\n",
        "print(\"\\nIPC NOUN SEARCH URL: \",ipc_noun_search_url,file=f)\n",
        "print(\"\\nIPC NOUN SEARCH URL: \",ipc_noun_search_url)\n",
        "print(\"\\nIPC CHUNK SEARCH URL: \",ipc_chunk_search_url,file=f)\n",
        "print(\"\\nIPC CHUNK SEARCH URL: \",ipc_chunk_search_url)\n",
        "\n",
        "if choice_text.lower()==\"d\":\n",
        "  os.rename('/content/drive/My Drive/MYOUTPUT.txt','/content/drive/My Drive/MYOUTPUT-D.txt')\n",
        " \n",
        "else: \n",
        "  os.rename('/content/drive/My Drive/MYOUTPUT.txt','/content/drive/My Drive/MYOUTPUT-C.txt') \n",
        "\n",
        "\n",
        "  \n",
        "f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Description or Claim ? : d\n",
            "INPUT IS DESCRIPTION TEXT\n",
            "\n",
            "For prior art search insert the priority or filing date in format:yyyymmdd  20170407\n",
            "Insert description text here:  INNOVATION IN WOOD-PVC COMPOSITE 5 Technical field of the invention SUMMARY OF THE INVENTION The present invention provides novelty in wood-PVC composite containing 2-EthylHexyl Oleate process aid. It is related to. 10 State of the art Wood-PVC composites which are internationally defined as C WPC;; of timber or During the construction of furniture exposed a significant amount of wood pieces and sawdust. obtained cellulose fibers with a small amount of polymer-based plastics, special processes 15 and some properties of both wood and plastic. are all recyclable, high quality products. Natural timber wood products made using sunlight, aging, moisture, insect it is perishable and laborious. The natural wood appearance of plastic products and it has no easy processability and high expansion rate. These negativities 20 wood plastic composites. In the production of wood-PVC composite materials in the state of the art all of the process aids used are all solid granules or powder It shaped. 25 Nowadays, the most preferred process assistant is wood-PVC thermal degradation is experienced in the composite material production process, hydrocarbon, carbon monoxide, carbon dioxide gases and fumes that irritate the skin are released. Internal structure of the product It consists of 30 visible gaps. In addition, the process assistant in the production process The amount of PVC (weight) should be used between 3% - 4%. This is-2- wood-PVC composite cost increases. Consequently, the existence of the above problems and the inadequacy of the solutions available are in the technical field of the process aid used in the production of woodPVC composite materials. 5 made an improvement. OBJECTS OF THE INVENTION Based on the prior art, the main object of the invention is wood-PVC composite. 10 2-EthylHexyl Oleate is used as process aid in the production of materials. Another main object of the invention is the solid granule or powder of the prior art. unlike process aids. Another main object of the invention is the low volatility and content of paraffin. it does not smoke at the processing temperature in the production process. Another main object of the invention is to provide surface properties, light and environmental resistance. 20 Another main object of the invention is to determine the amount (weight) of PVC in the state of the art. The use of process assistant used is used in 3% to 4% of the weight of PVC, the ratio is reduced from 0.5% to 01.5%. Thus, wood-PVC cost reduction was achieved in composite production. 25 Another main object of the present invention is to provide the interior of the final product made of wood-PVC composite material. The absence of visible gaps in the structure. Brief description of the invention 30 The present invention relates to novelty in wood-PVC composite. In the invention, process aid-3- 2-EthylHexyl Oleate was used. Detailed description of the invention 5 Wood-PVC composite material mixing ratios are as follows; PVC 45-55% SAW 35-40% CALCITE 5-10% 10 STABILIZER 1.5-3% COLOR PIGMENT 0.85-1.5% IMPACT ADJUSTMENT 1-1.5% UV ADDITIVE 0.2-0.85% PROCESS ASSISTANT 0.2-0.85% 15 In the prior art, process aid addition rates depend on the amount of PVC in the mixture is between 3% and 4% of the PVC involved. In our invention, it is between 0.5% and 1.5%. The ratios mentioned above are the general mixing ratio. Mixture according to these ratios made and mixed in hot mixer, forming in extruder machine 20 are realized. In the invention, 2-EthylHexyl Oleate is used as process aid and is in liquid form. Promise Thanks to the process assistant, disadvantages have been eliminated. 25 Wood shavings are used as wood in the invention. Mushroom powder instead of wood shavings, fibers in palm tree trunks, paddy husk or corn tassel available. 30\n",
            "\n",
            "IPC sentence:   The present invention relates to novelty in wood-PVC composite. \n",
            "\n",
            "ipc_sent listesi  : The present invention relates to novelty in wood-PVC composite. \n",
            "\n",
            "doc_ipc_sent:   The present invention relates to novelty in wood-PVC composite.\n",
            "\n",
            " IPC NOUN SET LIST:  ['novelty', 'wood', 'composite', 'PVC']\n",
            "\n",
            " IPC CHUNK SET LIST:  ['wood-PVC composite', 'novelty']\n",
            "SORTED POSSIBLE REFERENCES REGARDING FREQUENCY IN DESCENDING ORDER: \n",
            "\n",
            "1)-  special processes 15\n",
            "2)-  These negativities 20\n",
            "3)-  the invention 30\n",
            "4)-  the invention 5\n",
            "5)-  IMPACT ADJUSTMENT 1\n",
            "6)-  0.85% 15\n",
            "7)-  extruder machine 20\n",
            "\n",
            "CRITICAL IPC KEYWORDS (comprising system,arrangement,product,device,method etc.):\n",
            "\n",
            "material production\n",
            "\n",
            "SORTED IPC KEYWORDS QUERY FORMAT REGARDING FREQUENCY IN DESCENDING ORDER:\n",
            "\n",
            "1)-  process_aid+\n",
            "2)-  process_assistant+\n",
            "3)-  pvc_composite+\n",
            "4)-  production_proces+\n",
            "\n",
            "UNIQUE KEYWORDS (freq=1): \n",
            "\n",
            "invention SUMMARY\n",
            "wood pieces\n",
            "cellulose fibers\n",
            "quality products\n",
            "timber wood\n",
            "wood products\n",
            "wood appearance\n",
            "expansion rate\n",
            "wood plastic\n",
            "plastic composites\n",
            "material production\n",
            "carbon monoxide\n",
            "carbon dioxide\n",
            "dioxide gases\n",
            "cost increases\n",
            "processing temperature\n",
            "surface properties\n",
            "01.5%\n",
            "PVC cost\n",
            "cost reduction\n",
            "material mixing\n",
            "mixing ratios\n",
            "% IMPACT\n",
            "IMPACT ADJUSTMENT\n",
            "% UV\n",
            "aid addition\n",
            "addition rates\n",
            "mixing ratio\n",
            "extruder machine\n",
            "Mushroom powder\n",
            "wood shavings\n",
            "palm tree\n",
            "\n",
            "PROBABLE PATENW QUERY FOR IPC OR SIMILAR DOCUMENTS : \n",
            "\n",
            "and process_aid+,process_assistant+,pvc_composite+\n",
            "\n",
            "FREQUENCY SEARCH URL:  https://patents.google.com/?q=(process+aid)&q=(process+assistant)&q=(pvc+composite)&before=publication:20170407&clustered=true\n",
            "\n",
            "COMPOUND NOUN SEARCH URL:  https://patents.google.com/?q=(process+aid)&q=(process+assistant)&q=(pvc+composite)&q=(novelty)&q=(wood)&q=(composite)&q=(PVC)&before=publication:20170407&clustered=true\n",
            "\n",
            "COMPOUND CHUNK SEARCH URL:  https://patents.google.com/?q=(process+aid)&q=(process+assistant)&q=(pvc+composite)&q=(wood-PVC+composite)&q=(novelty)&before=publication:20170407&clustered=true\n",
            "\n",
            "IPC NOUN SEARCH URL:  https://patents.google.com/?q=(novelty)&q=(wood)&q=(composite)&q=(PVC)&before=publication:20170407&clustered=true\n",
            "\n",
            "IPC CHUNK SEARCH URL:  https://patents.google.com/?q=(wood-PVC+composite)&q=(novelty)&before=publication:20170407&clustered=true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqiJ49h_xSCa",
        "colab_type": "code",
        "outputId": "15342210-c244-4ad1-82a4-7de16ff48aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "# ex: url= 'https://patents.google.com/?q=%28base+lock%29&q=%28lock+folding%29&q=%28folding+mechanism%29&q=%28base+lock+mechanism%29&q=%28seat+lock+folding+mechanism%29&q=%28vehicle+rear+seat%29&q=B60N2%252f00&q=weight+housing&q=rotation+bracket&q=pivoting+bracket&q=bolt&q=bearing&before=publication:20140627&clustered=true'\n",
        "df = pd.read_csv('/content/drive/My Drive/gps-2014-07578.csv')\n",
        "#df[url].index[0][0]  #'id'\n",
        "#df.index # ('DE-202009002580-U1', ...), alt alta hep böyle\n",
        "\n",
        "#df[url].index[0][0]  #'id'\n",
        "#df[url].index[1][0] #'CN-103380025-A'  #multiindex csv\n",
        "#df[url].index[2][0] #'WO-9911488-A1'\n",
        "#df[url].index[3][0] #'DE-10127067-A1'\n",
        "\n",
        "range_documents=int(input(\"Enter number of documents+1: \"))\n",
        "for i in range(1,range_documents):\n",
        "  print(str(df['search URL:'].index[i][0]).replace('-','')) \n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter number of documents+1: 88\n",
            "CN103380025A\n",
            "WO9911488A1\n",
            "DE10127067A1\n",
            "US2012019037A1\n",
            "EP0844939B1\n",
            "EP0305727A2\n",
            "CN1125739C\n",
            "CN101965276A\n",
            "CN100375687C\n",
            "DE102009010226A1\n",
            "EP0769412B1\n",
            "DE60207263T2\n",
            "US7159923B2\n",
            "DE19749780A1\n",
            "DE60111478T2\n",
            "JP4994083B2\n",
            "CN103313875A\n",
            "US8138908B2\n",
            "EP1325836A2\n",
            "DE3800896C2\n",
            "US2011031055A1\n",
            "DE19910085C1\n",
            "EP1429938A1\n",
            "CN103249593A\n",
            "CN1047131C\n",
            "KR20080100499A\n",
            "FR2855112A1\n",
            "US2010052390A1\n",
            "CN102143862B\n",
            "DE102011116376A1\n",
            "DE202009002580U1\n",
            "DE202009002581U1\n",
            "US7648164B2\n",
            "WO0212746A1\n",
            "ES2244950T3\n",
            "KR100315960B1\n",
            "CN1189345C\n",
            "US4483653A\n",
            "WO2004098944A1\n",
            "US7156442B2\n",
            "US4542917A\n",
            "DE4325244C2\n",
            "US5669668A\n",
            "US2005269861A1\n",
            "DE3725591A1\n",
            "EP0047761A1\n",
            "GB2074442A\n",
            "JPH0872595A\n",
            "JP2001504058A\n",
            "WO2009079668A2\n",
            "DE10159847A1\n",
            "WO2013182242A1\n",
            "US6886889B2\n",
            "WO2013115931A1\n",
            "CN101443236A\n",
            "WO2013088165A1\n",
            "DE3605774C2\n",
            "EP1564067A1\n",
            "US2443552A\n",
            "US2005184549A1\n",
            "EP1106422A1\n",
            "EP1901939A2\n",
            "US6499712B1\n",
            "CN103038097A\n",
            "CA2773512A1\n",
            "US2014159436A1\n",
            "CN101084133A\n",
            "EP2144784A2\n",
            "CN103101454A\n",
            "JP2009226982A\n",
            "US3964785A\n",
            "EP2437960A1\n",
            "DE20302464U1\n",
            "JP5441044B1\n",
            "CN103209859A\n",
            "EP0468348B1\n",
            "DE4431248C1\n",
            "DE3929957A1\n",
            "US8419135B2\n",
            "CN101142110A\n",
            "CN101844527B\n",
            "FR2838687A1\n",
            "US5022669A\n",
            "US6326704B1\n",
            "CN1043008C\n",
            "EP0759715B1\n",
            "JPH07298947A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jifdeNgB30",
        "colab_type": "code",
        "outputId": "fe138e01-828a-433e-d450-1aa37eb8009f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(type(ipc_sent))\n",
        "len(ipc_sent)\n",
        "print(ipc_sent)\n",
        "type(ipc_sent[0])\n",
        "text=\"Eating apple is not an easy task.I said apple\"\n",
        "doc = nlp(text)\n",
        "liste=[]\n",
        "for token in doc:\n",
        "  if token.pos_=='NOUN':\n",
        "    liste.append(token)\n",
        "\n",
        "print(\"liste: \",liste)\n",
        "stringlist=[]\n",
        "for t in liste:\n",
        " stringlist.append(t.text)\n",
        "print(\"stringlist: \",stringlist)\n",
        "myset=set(stringlist)\n",
        "print(\"myset: \",myset)\n",
        "doc=nlp(\"concern\")\n",
        "doc[0].pos_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[The present invention concerns too particularly novel indolizines derivatives with inhibitory effects towards kinase proteins., The present invention concerns then particularly compounds capable to inhibit protein kinases., The present invention concerns particularly the compounds of general formula (I) as defined above which are compounds of formula (, The present invention concerns particularly the compounds of formula (ICC) as defined above in which R2 represents halogeno (Br, Cl, I or F) or cyano., The present invention concerns particularly the compounds of formula (ICC) as defined above in which R3 represents hydrogen, methyl, trifluoromethyl, optionally substitutedaryl, cyclopropyl, tetrahydropyran-4-yl, optionally substituted pyridinyl (more especially pyrid-3-yl or 4-methyl-pyrid-3-yl) or 1-methanesulfonylpiperidin-4-yl.., The present invention concerns particularly the compounds of formula (ICC) as defined above in which R3 represents optionally substituted aryl., The present invention concerns particularly the compounds of formula (ICC) as defined above in which R3 represents phenyl., The present invention concerns particularly the compounds of formula (ICC) as defined above in which R4C represents NH R4 in which R4 represents alkyl, cycloalkyl, heterocycloalkyl, arylalkyl, cycloalkylalkyl, heteroarylalkyl, heterocycloalkylalky, aryl or heteroaryl , each optionally substituted ., The present invention concerns particularly the compounds of formula (ICC) as defined above in which R4C represents NH R4 in which R4 represents alkyl, aryl or cycloalkyl, all optionally substituted., The present invention concerns particularly the compounds of formula (ICC) as defined in the previous claims in which:- R2 is halogeno or cyano; R3 is optionally substituted aryl (especially phenyl), and R4C represents NH R4 in which R4 represents alkyl, cycloalkyl, heterocycloalkyl, arylalkyl, cycloalkylalkyl, heteroarylalkyl, heterocycloalkylalkyl, aryl or heteroaryl, each optionally substituted, and their corresponding N-oxides, and their prodrugs; and pharmaceutically acceptable salts and solvates (e.g. hydrates) of such compounds and their N-oxides and their prodrugs., The present invention concerns particularly the compounds of formula (ICC) as defmed above in which:-, The present invention concerns particularly the compounds of formula (ICC) as defined above in which R2 is chloro or cyano; R3 is phenyl and, The present invention concerns particularly the compounds of formula (ICC) as defined above in which R2 is chloro or cyano; R3 is phenyl and, The present invention concerns particularly the following compounds of formula (ICC):, The present invention concerns then particularly the following compounds of formula (ICC):, The present invention concerns more particularly, as medicinal products, the products as defined by formula (ICC), the said products of formula (ICC), being in any possible racemic, enantiomeric or diastereoisomeric isomer form, and also the addition salts with pharmaceutically acceptable mineral and organic acids or with pharmaceutically acceptable mineral and organic bases of the said products of formula (ICC) ., The invention also relates to pharmaceutical compositions containing, as active principle, at least one of the products of formula (I) as defined above, or a pharmaceutically acceptable salt of this product or a prodrug of this product and, where appropriate, a pharmaceutically acceptable support., The present invention concerns then the products of formula (I) as defined above as kinases inhibitors, the said products of formula (I) being in any possible racemic, enantiomeric or diastereoisomeric isomer form, and also the addition salts with pharmaceutically acceptable mineral and organic acids or with pharmaceutically acceptable mineral and organic bases of the said products of formula (I)., The present invention concerns then products of formula (I) as defined above as FAK inhibitors., The present invention concerns particularly products of formula (I) as defined above as IGF1R inhibitors., The present invention concerns too products of formula (I) as defined above as FAK inhibitors., The present invention concerns particularly the products of formula (ICC) as defmed above as IGF1R inhibitors.]\n",
            "liste:  [apple, task, apple]\n",
            "stringlist:  ['apple', 'task', 'apple']\n",
            "myset:  {'apple', 'task'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0K7rV-cdgIa",
        "colab_type": "code",
        "outputId": "4d88e4c1-1693-4623-9bd1-d8190a8aeb6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
        "\n",
        "wordforSimilarity= input(\"Insert a word for similar matches: \")\n",
        "wordforSimilarity = wordforSimilarity.lower()\n",
        "new_vector = nlp.vocab[wordforSimilarity].vector\n",
        "\n",
        "computed_similarities = []\n",
        "\n",
        "for word in nlp.vocab:\n",
        "    # Ignore words without vectors and mixed-case words:\n",
        "    if word.vector_norm > 0:\n",
        "        if word.is_lower:\n",
        "          if word.is_alpha:\n",
        "            similarity = cosine_similarity(new_vector, word.vector)\n",
        "            computed_similarities.append((word, similarity))\n",
        "\n",
        "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
        "\n",
        "print([w[0].text for w in computed_similarities[:20]])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Insert a word for similar matches: WORD\n",
            "['word', 'phrase', 'words', 'meaning', 'phrases', 'language', 'spoken', 'dictionary', 'spelling', 'referring', 'means', 'saying', 'verb', 'term', 'speak', 'sentence', 'spelled', 'meant', 'name', 'speaking']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeWfHSrK-8FK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IPC-PREDICT-NOUN PHRASE\n",
        "#2 AŞAMALI- 3 HANELİ IPC\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from scipy import spatial\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "my_input = input(\"Insert the first meaningful sentence in description regarding ipc: \")\n",
        "my_input=my_input.lower()\n",
        "\n",
        "\n",
        "input_doc = nlp(my_input)\n",
        "\n",
        "#for ent in doc.ents:\n",
        "#  print(\"ents: \", ent.text, \" \", ent.label_)\n",
        "\n",
        "#nlp.tokenizer.add_special_case('-', [{ORTH: '-', POS:ADP}])\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "#pattern 00,01,10,11 : referanslar için (ör: a chassis, the chassis, vehicle chassis)\n",
        "patternipc1 = [{'POS': 'NOUN', 'OP': '!'},{'POS':'NOUN'},{'POS':'NOUN'},{'POS':'NOUN'},{'POS': 'NOUN', 'OP': '!'}]\n",
        "patternipc2 = [{'POS': 'NOUN', 'OP': '!'},{'POS':'NOUN'},{'POS':'NOUN'},{'POS': 'NOUN', 'OP': '!'}]\n",
        "patternipc3 = [{'POS': 'NOUN', 'OP': '!'},{'POS':'ADJ'},{'POS':'NOUN'},{'POS': 'NOUN', 'OP': '!'}]\n",
        "patternipc4 = [{'POS': 'NOUN', 'OP': '!'},{'POS':'ADJ'},{'POS':'NOUN'},{'POS':'NOUN'},{'POS': 'NOUN', 'OP': '!'}]\n",
        "patternipc5 = [{'POS': 'NOUN', 'OP': '!'},{'POS':'NOUN'},{'POS': 'NOUN', 'OP': '!'}]\n",
        "matcher.add('IPC',None,patternipc1,patternipc2,patternipc3,patternipc4,patternipc5)\n",
        "found_matches = matcher(input_doc)\n",
        "\n",
        "print('\\nPOSSIBLEIPC WORDS:\\n')\n",
        "if len(found_matches)==0:\n",
        "  print(\"NO POSSIBLE IPC WORD found with given format\\n\")\n",
        "\n",
        "list_ipcwords = []\n",
        "for match_id, start, end in found_matches:\n",
        "  string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "  span = input_doc[start:end]                    # get the matched span\n",
        "  print(match_id, string_id, start, end, span.text)\n",
        "  list_ipcwords.append(span.text)\n",
        "print('\\n')\n",
        "\n",
        "ipctext = ' '.join(list_ipcwords)\n",
        "rawdoc = nlp(ipctext)\n",
        "apptext=[]\n",
        "for token in rawdoc:\n",
        "  if token.pos_ == 'NOUN' or token.pos_ == 'ADJ':\n",
        "    apptext.append(token.text)\n",
        "# unique ifadeler bulunup listeye dahil edilir, listeden tek bir string(unique_text) üretilir,bu string de nlp ile doc objesine dönüştürülür \n",
        "unique_list = [] \n",
        "for x in apptext:\n",
        "  if x not in unique_list: \n",
        "    unique_list.append(x) \n",
        "\n",
        "unique_text = ' '.join(unique_list)\n",
        "appdoc = nlp(unique_text)\n",
        "print(\"\\nAPPDOC: \",appdoc)\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/ipc.tsv', sep='\\t')\n",
        "\n",
        "# ilk cümle başarısız olursa alttaki 2 yorum koduna devam edilebilir\n",
        "#app = input(\"insert critical words for ipc: \")\n",
        "#appdoc= nlp(app)\n",
        "probIpc=[]\n",
        "for i in(range(len(df['Definition']))):\n",
        "  print(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "  probIpc.append(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "\n",
        "print(\"FIRST FIVE MAXIMUM VALUES:\\n\")\n",
        "\n",
        "df['predictionValue']=pd.Series(probIpc)\n",
        "print(df.sort_values(by='predictionValue', ascending = False))\n",
        "print(\"\\n\")\n",
        "\n",
        "try:\n",
        "  print(\"VALUES GREATER THAN 0.5:\\n\",df[df['predictionValue'] > 0.5])\n",
        "except:\n",
        "  print('NO PREDICTION VALUE GREATER THAN 0.5\\n')\n",
        "\n",
        "\n",
        "answer=input(\"\\nIf you are not satisfied with the results do you want to insert your own noun phrases for ipc ?\\n\")\n",
        "\n",
        "if answer.lower() == \"y\" or answer.lower() == \"yes\":\n",
        "  app = input(\"Insert critical noun phrases for ipc wihout punctuation (e.g image processor, marine, communication network ): \")\n",
        "  appdoc= nlp(app)\n",
        "  probIpc=[]\n",
        "  for i in(range(len(df['Definition']))):\n",
        "    print(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "    probIpc.append(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "  print(\"\\nMAXIMUM VALUES:\\n\")\n",
        "  df['predictionValue']=pd.Series(probIpc)\n",
        "  print(df.sort_values(by='predictionValue', ascending = False).head(20))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "  try:\n",
        "    print(\"VALUES GREATER THAN 0.5:\\n\",df[df['predictionValue'] > 0.5])\n",
        "    print(\"\\nYou can run again for new search...\")\n",
        "  except:\n",
        "    print('NO PREDICTION VALUE GREATER THAN 0.5\\n')\n",
        "\n",
        "else:\n",
        "  print(\"\\nYou can run again for new search...\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KoLmTHHqon7u",
        "colab": {}
      },
      "source": [
        "df.sort_values(by='predictionValue', ascending = False).head(40)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iT2NSukytjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail(60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHr7fl-fsmf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app=input(\"app: \")\n",
        "ipc=input(\"ipc: \")\n",
        "docipc = nlp(ipc)\n",
        "docapp = nlp(app)\n",
        "print(docapp.vector_norm,docipc.vector_norm)\n",
        "print(\"app:\",docapp.has_vector)\n",
        "print(\"ipc:\",docipc.has_vector)\n",
        "print(docapp.similarity(docipc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyWwAMHtPOPr",
        "colab_type": "code",
        "outputId": "95555619-f7d5-4280-cd7c-11af912b82d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "entry=input(\"Bir cümle yaz: \")\n",
        "doc=nlp(entry.lower())\n",
        "for chunk in doc.noun_chunks:\n",
        "  liste=[chunk.text for chunk in doc.noun_chunks]\n",
        "print(\"liste: \",liste)\n",
        "for token in doc:\n",
        "  print(token.text,token.lemma_,token.pos_,token.tag_,token.dep_,token.shape_,token.is_alpha,token.is_stop,token.like_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bir cümle yaz: the present invention relates to a base lock mechanism for vehicle rear seats.a seat lock folding mechanism that provides a wide variety of applications.\n",
            "liste:  ['the present invention', 'a base lock mechanism', 'vehicle rear seats.a seat lock folding mechanism', 'a wide variety', 'applications']\n",
            "the the DET DT det xxx True True False\n",
            "present present ADJ JJ amod xxxx True False False\n",
            "invention invention NOUN NN nsubj xxxx True False False\n",
            "relates relate VERB VBZ ROOT xxxx True False False\n",
            "to to ADP IN prep xx True True False\n",
            "a a DET DT det x True True False\n",
            "base base NOUN NN compound xxxx True False False\n",
            "lock lock NOUN NN compound xxxx True False False\n",
            "mechanism mechanism NOUN NN pobj xxxx True False False\n",
            "for for ADP IN prep xxx True True False\n",
            "vehicle vehicle NOUN NN nmod xxxx True False False\n",
            "rear rear ADJ JJ amod xxxx True False False\n",
            "seats.a seats.a PUNCT . compound xxxx.x False False False\n",
            "seat seat NOUN NN compound xxxx True False False\n",
            "lock lock NOUN NN compound xxxx True False False\n",
            "folding folding NOUN NN compound xxxx True False False\n",
            "mechanism mechanism NOUN NN pobj xxxx True False False\n",
            "that that DET WDT nsubj xxxx True True False\n",
            "provides provide VERB VBZ relcl xxxx True False False\n",
            "a a DET DT det x True True False\n",
            "wide wide ADJ JJ amod xxxx True False False\n",
            "variety variety NOUN NN dobj xxxx True False False\n",
            "of of ADP IN prep xx True True False\n",
            "applications application NOUN NNS pobj xxxx True False False\n",
            ". . PUNCT . punct . False False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhtaEqr6Qw0-",
        "colab_type": "code",
        "outputId": "2d3216f1-58bb-46c6-aea1-0637d942f432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#IPC PREDICT-NOUN-CHUNKS (+ (TOKEN.TAG_=VBG) ?)\n",
        "# 2 AŞAMALI\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from scipy import spatial\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "my_input = input(\"Insert the first meaningful sentence in description regarding ipc: \")\n",
        "my_input=my_input.lower()\n",
        "\n",
        "#--------\n",
        "input_doc = nlp(my_input)\n",
        "liste_chunk=[]\n",
        "for chunk in input_doc.noun_chunks:\n",
        "  print(\"CHUNK: \",chunk)\n",
        "  for i in(range(len(chunk))):\n",
        "    if (chunk[i].is_stop == False and chunk[i].text != \"-\" and chunk[i].is_punct == False and chunk[i].pos_ != 'NUM'):\n",
        "      liste_chunk.append(chunk[i].text)\n",
        "#---------\n",
        "\n",
        "print(\"CHUNK LİSTESİ: \",liste_chunk)\n",
        "\n",
        "ipctext = ' '.join(liste_chunk)\n",
        "\n",
        "\n",
        "appdoc = nlp(ipctext)\n",
        "print(\"\\nAPPDOC: \",appdoc)\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/ipc.tsv', sep='\\t')\n",
        "\n",
        "\n",
        "probIpc=[]\n",
        "for i in(range(len(df['Definition']))):\n",
        "  print(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "  probIpc.append(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "\n",
        "print(\"\\nMAXIMUM VALUES: \\n\")\n",
        "\n",
        "df['predictionValue']=pd.Series(probIpc)\n",
        "print(df.sort_values([\"predictionValue\"], ascending = False).head(20))\n",
        "print(\"\\n\")\n",
        "\n",
        "#burası çok önemli yeni df'nin indexi sıfırlanmalı\n",
        "df2 = df.sort_values([\"predictionValue\"], ascending = False)\n",
        "df2 = df2.reset_index(drop=True)\n",
        "\n",
        "#most prop ipc list, df2'deki IPC verileri ile oluşturulur\n",
        "most_prob_ipc_list=[]\n",
        "for i in range(0,20):\n",
        "  most_prob_ipc_list.append((df2['IPC'][i],i))\n",
        "\n",
        "final_ipc_df1 = pd.DataFrame(most_prob_ipc_list, columns =['IPC','FIRST-INDEX'])\n",
        "#print(\"MOST PROBABLE IPC LIST: \\n\",most_prob_ipc_list)\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  print(\"\\nVALUES GREATER THAN 0.5:\\n\",df[df['predictionValue'] > 0.5])\n",
        "except:\n",
        "  print('NO PREDICTION VALUE GREATER THAN 0.5\\n')\n",
        "\n",
        "\n",
        "answer=input(\"\\nIf you are not happy with the results do you want to insert your own noun phrases for ipc ?\\n\")\n",
        "\n",
        "if answer.lower() == \"y\" or answer.lower() == \"yes\":\n",
        "  app = input(\"Insert critical noun phrases for ipc wihout punctuation (e.g image processor, marine, communication network ): \")\n",
        "  appdoc= nlp(app)\n",
        "  probIpc=[]\n",
        "  for i in(range(len(df['Definition']))):\n",
        "    print(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "    probIpc.append(appdoc.similarity(nlp(str(df['Definition'][i]))))\n",
        "  print(\"\\nMAXIMUM VALUES:\\n\")\n",
        "  df['predictionValue']=pd.Series(probIpc)\n",
        "  print(df.sort_values([\"predictionValue\"], ascending = False).head(20))\n",
        "\n",
        "  print(\"\\nFIRST PREDICTION VALUES:\\n\", df2.head(20))\n",
        "  \n",
        "  # ilk df2'dn farklı olarak ikinci df2 oluşturulur sonuçta her iki df2'deki IPC verileri ile most prob ipc list oluşur\n",
        "  df2=df.sort_values([\"predictionValue\"], ascending = False)\n",
        "  df2 = df2.reset_index(drop=True)\n",
        "\n",
        "  most_prob_ipc_list2=[]\n",
        "  for m in range(0,20):\n",
        "    most_prob_ipc_list2.append((df2['IPC'][m],m))\n",
        "  #print(\"MOST PROBABLE IPC LIST: \\n\",most_prob_ipc_list)\n",
        "  final_ipc_df2 = pd.DataFrame(most_prob_ipc_list2, columns =['IPC','SECOND-INDEX'])\n",
        "  result_df = pd.merge(final_ipc_df1,final_ipc_df2, on='IPC', how='outer', indicator=True)\n",
        "\n",
        "  #result_df = pd.merge(final_ipc_df1,final_ipc_df2, on='IPC')\n",
        "  #result_df = final_ipc_df1.append(final_ipc_df2, sort=False)\n",
        "  print(\"\\nRESULT:\\n\",result_df)\n",
        "  #final_ipc_list = [(x, most_prob_ipc_list.count(x),most_prob_ipc_list.) for x in set(most_prob_ipc_list)]\n",
        "  #print (\"IPC FREQUENCY IN BOTH METHODS: \", final_ipc_list) \n",
        "  \n",
        "  #final_ipc_df = pd.DataFrame(final_ipc_list, columns =['IPC', 'FREQUENCY', 'FIRST-INDEX']) \n",
        "  #-----alttaki komut önemli, son sorting\n",
        "  result_df['TOTAL-INDEX'] = result_df['FIRST-INDEX']+result_df['SECOND-INDEX']\n",
        "\n",
        "  final_sorted_ipc_df = result_df.sort_values([\"TOTAL-INDEX\"], ascending = True)\n",
        "  print(\"\\nIPC FREQUENCY IN BOTH METHODS:\\n \",final_sorted_ipc_df)\n",
        "\n",
        "  try:\n",
        "    print(\"\\nVALUES GREATER THAN 0.5:\\n\",df[df['predictionValue'] > 0.5])\n",
        "    print(\"\\nYou can run again for new search...\")\n",
        "  except:\n",
        "    print('NO PREDICTION VALUE GREATER THAN 0.5\\n')\n",
        "\n",
        "else:\n",
        "  print(\"\\nYou can run again for new search...\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CHUNK:  the present invention\n",
            "CHUNK:  a seat lock folding mechanism\n",
            "CHUNK:  the base locking mechanisms\n",
            "CHUNK:  the vehicle rear seats\n",
            "CHUNK LİSTESİ:  ['present', 'invention', 'seat', 'lock', 'folding', 'mechanism', 'base', 'locking', 'mechanisms', 'vehicle', 'rear', 'seats']\n",
            "\n",
            "APPDOC:  present invention seat lock folding mechanism base locking mechanisms vehicle rear seats\n",
            "0.3520770559469375\n",
            "0.23400545989873545\n",
            "0.18283248106250538\n",
            "0.24915880483641636\n",
            "0.210015642972904\n",
            "0.27690096124137303\n",
            "0.1784576325937309\n",
            "0.30036391823235814\n",
            "0.2453396577490228\n",
            "0.5361087962766911\n",
            "0.33312083129967934\n",
            "0.44392332147423325\n",
            "0.29026175287148803\n",
            "0.24611670559769752\n",
            "0.23995781419088086\n",
            "0.4003023389776023\n",
            "0.25180479264575656\n",
            "0.6238440044842616\n",
            "0.21380170141996524\n",
            "0.5091597863839761\n",
            "0.5762322185408523\n",
            "0.4096706342049961\n",
            "0.3943085989134312\n",
            "0.43841048568280727\n",
            "0.5281815061710757\n",
            "0.32686427772787324\n",
            "0.6135884036561912\n",
            "0.3501763941485197\n",
            "0.5525637522735125\n",
            "0.43883057009505627\n",
            "0.4272043384401846\n",
            "0.33019516527729353\n",
            "0.5307422228854853\n",
            "0.31777576455973133\n",
            "0.3507784980168172\n",
            "0.5191805227923132\n",
            "0.3982158908394167\n",
            "0.45128302363414924\n",
            "0.2542124315227376\n",
            "0.35838152015938624\n",
            "0.26726893704456917\n",
            "0.7540803955960723\n",
            "0.2817831460760563\n",
            "0.6380304764788598\n",
            "0.35394761351613846\n",
            "0.35864186146904076\n",
            "0.6254013753510963\n",
            "0.48687097390665696\n",
            "0.5324114932573518\n",
            "0.42277621847472846\n",
            "0.0\n",
            "0.17871924335554454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.29784924952472536\n",
            "0.29943527110022966\n",
            "0.3414304174084213\n",
            "0.31239292401561564\n",
            "0.07136732019816829\n",
            "0.22038779511399023\n",
            "0.2632830608009358\n",
            "0.2073811721287854\n",
            "0.23159066855741828\n",
            "0.33242083645283105\n",
            "0.26759156045128524\n",
            "0.31650369954510077\n",
            "0.1337132929582743\n",
            "0.3893512285821593\n",
            "0.4135056415353359\n",
            "0.30617791689484636\n",
            "0.5263438293836797\n",
            "0.0950562375794\n",
            "0.21432889194457666\n",
            "0.3129669865059266\n",
            "0.37538519002904874\n",
            "0.32914229149258856\n",
            "0.29664785964504714\n",
            "0.2978254951555383\n",
            "0.20993496554586027\n",
            "0.33892666460270354\n",
            "0.28787733199534365\n",
            "0.2351929802957803\n",
            "0.3116019122122057\n",
            "0.39872624615884444\n",
            "0.29933430312149323\n",
            "0.46388997282819017\n",
            "0.5182214382721513\n",
            "0.6315734149374624\n",
            "0.2868088818775357\n",
            "0.562913404612515\n",
            "0.5392027348428928\n",
            "0.5838126057799796\n",
            "0.48374090489957705\n",
            "0.590447010411643\n",
            "0.6239228873761803\n",
            "0.4170808368791763\n",
            "0.32328981819862207\n",
            "0.19418411453733717\n",
            "0.28444087466871537\n",
            "0.47076314862846386\n",
            "0.394473928397505\n",
            "0.5234229656128914\n",
            "0.25665017798194983\n",
            "0.43358958163419226\n",
            "0.40677762757482716\n",
            "0.2910754778049115\n",
            "0.43777114545977797\n",
            "0.37337350476997955\n",
            "0.09817221563974171\n",
            "0.1926186486063433\n",
            "0.6588376119358124\n",
            "0.4592010014568724\n",
            "0.47862775343166275\n",
            "0.584431762711488\n",
            "0.5227913758637864\n",
            "0.43343512695068676\n",
            "0.5843343533521385\n",
            "0.6278464419725988\n",
            "0.34229674678228644\n",
            "0.520232916478847\n",
            "0.5966847095716667\n",
            "0.43168703563383914\n",
            "0.501247333050417\n",
            "0.6185157095244807\n",
            "\n",
            "MAXIMUM VALUES: \n",
            "\n",
            "     IPC                                         Definition  predictionValue\n",
            "41   B60  vehicle wheel tyre suspension amphibious passe...         0.754080\n",
            "108  G05  physics regulating systems control systems aut...         0.658838\n",
            "43   B62  hand cart preambulator sledge trailer steering...         0.638030\n",
            "85   E06                                 door window ladder         0.631573\n",
            "115  G12  calibrating physics instrument apparatus indic...         0.627846\n",
            "46   B65  conveying packing storing packaging labelling ...         0.625401\n",
            "92   F16  jointing fastening gearing damping vibration v...         0.623923\n",
            "17   B03  electric electrostatic magnetic separation flu...         0.623844\n",
            "121  H05  electric ohmic-resistance heating arc lamps el...         0.618516\n",
            "26   B23                         machine tool metal working         0.613588\n",
            "118  H02  distribution generation electric power dynamo-...         0.596685\n",
            "91   F15            actuator servomotor fluid dynamics flow         0.590447\n",
            "111  G08  signalling calling systems telegraph burglar t...         0.584432\n",
            "114  G11  information storage record carrier digital sto...         0.584334\n",
            "89   F03                  wind turbine spring weight motor          0.583813\n",
            "20   B06                 transmitting mechanical vibration          0.576232\n",
            "87   F01  steam engines piston lubricating machines cool...         0.562913\n",
            "28   B25                  hand tool bench hammer percussive         0.552564\n",
            "88   F02  combustion engines jet propulsion ignition fue...         0.539203\n",
            "9    A45              umbrella purse luggage  walking stick         0.536109\n",
            "\n",
            "\n",
            "\n",
            "VALUES GREATER THAN 0.5:\n",
            "      IPC                                         Definition  predictionValue\n",
            "9    A45              umbrella purse luggage  walking stick         0.536109\n",
            "17   B03  electric electrostatic magnetic separation flu...         0.623844\n",
            "19   B05                         spraying atomising surface         0.509160\n",
            "20   B06                 transmitting mechanical vibration          0.576232\n",
            "24   B21                             punching shaping metal         0.528182\n",
            "26   B23                         machine tool metal working         0.613588\n",
            "28   B25                  hand tool bench hammer percussive         0.552564\n",
            "32   B29             plastics plastic state shaped plastics         0.530742\n",
            "35   B32      layer strata flat non-flatcellular honeycomb          0.519181\n",
            "41   B60  vehicle wheel tyre suspension amphibious passe...         0.754080\n",
            "43   B62  hand cart preambulator sledge trailer steering...         0.638030\n",
            "46   B65  conveying packing storing packaging labelling ...         0.625401\n",
            "48   B67  opening closing bottle jar filling liquid cont...         0.532411\n",
            "68   C23     coating metallic material enamelling corrosion         0.526344\n",
            "84   E05                                   locks keys safes         0.518221\n",
            "85   E06                                 door window ladder         0.631573\n",
            "87   F01  steam engines piston lubricating machines cool...         0.562913\n",
            "88   F02  combustion engines jet propulsion ignition fue...         0.539203\n",
            "89   F03                  wind turbine spring weight motor          0.583813\n",
            "91   F15            actuator servomotor fluid dynamics flow         0.590447\n",
            "92   F16  jointing fastening gearing damping vibration v...         0.623923\n",
            "99   F26                drying drying-system drying-chamber         0.523423\n",
            "108  G05  physics regulating systems control systems aut...         0.658838\n",
            "111  G08  signalling calling systems telegraph burglar t...         0.584432\n",
            "112  G09  cryptography ciphering deciphering educational...         0.522791\n",
            "114  G11  information storage record carrier digital sto...         0.584334\n",
            "115  G12  calibrating physics instrument apparatus indic...         0.627846\n",
            "117  H01  electric elements cables conductors resistors ...         0.520233\n",
            "118  H02  distribution generation electric power dynamo-...         0.596685\n",
            "120  H04  electric communication techniqe line transmiss...         0.501247\n",
            "121  H05  electric ohmic-resistance heating arc lamps el...         0.618516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e0dbfa40d684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nIf you are not happy with the results do you want to insert your own noun phrases for ipc ?\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3n2ViiFqrfB",
        "colab_type": "code",
        "outputId": "e948947b-4a49-40b9-b97c-2068e6452074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#IPC PREDICT-NOUN-CHUNKS-FULL IPC\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from scipy import spatial\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "my_input = input(\"Insert the first meaningful sentence in description regarding ipc: \")\n",
        "my_input = my_input.lower()\n",
        "\n",
        "#--------\n",
        "input_doc = nlp(my_input)\n",
        "\n",
        "\n",
        "liste_chunk=[]\n",
        "for chunk in input_doc.noun_chunks:\n",
        "  print(\"CHUNK: \",chunk)\n",
        "  for i in(range(len(chunk))):\n",
        "    if (chunk[i].is_stop == False and chunk[i].text != \"-\" and chunk[i].is_punct == False and chunk[i].pos_ != 'NUM'):\n",
        "      liste_chunk.append(chunk[i].text)\n",
        "#---------\n",
        "\n",
        "\n",
        "print(\"CHUNK LİSTESİ: \",liste_chunk)\n",
        "\n",
        "most_freq_tuple_list = Counter(liste_chunk).most_common(10)\n",
        "most_freq_noun_list = [ word for word,freq in most_freq_tuple_list]\n",
        "print(\"MOST FREQ NOUNS: \",most_freq_noun_list)\n",
        "\n",
        "#---------------------------------------------\n",
        "#burada en yüksek frekanslı kelimelerle bir tex oluşturulur ve sonrasında bu doc objesine dönüştürülür\n",
        "ipctext = ' '.join(most_freq_noun_list)\n",
        "\n",
        "appdoc = nlp(ipctext)\n",
        "print(\"\\nAPPDOC: \",appdoc)\n",
        "#--------------------------------------------\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/FULLIPCVEHICLE.tsv', sep='\\t')\n",
        "\n",
        "#BURADA DEF1 SÜTUNU İLE BENZERLİK DEĞERLERİ PROBIPC1 LİSTESİNE EKLENİR. DEF1 4 HANELİ IPC SINIFI İÇİN TANIMDIR\n",
        "probIpc1=[]\n",
        "for i in(range(len(df['IPC']))):\n",
        "  #print(appdoc.similarity(nlp(str(df['DEF1'][i]))))\n",
        "  probIpc1.append(appdoc.similarity(nlp(str(df['DEF1'][i]))))\n",
        "\n",
        "print(\"\\nMAXIMUM VALUES FOR DEF1: \\n\")\n",
        "\n",
        "df['predictionValue1']=pd.Series(probIpc1)\n",
        "print(df.sort_values([\"predictionValue1\"], ascending = False).head(20))\n",
        "print(\"\\n\")\n",
        "\n",
        "#BURADA DEF2 SÜTUNU İLE BENZERLİK DEĞERLERİ PROBIPC2 LİSTESİNE EKLENİR. DEF2 3 HANELİ IPC SINIFI İÇİN TANIMDIR\n",
        "probIpc2=[]\n",
        "for i in(range(len(df['IPC']))):\n",
        "  #print(appdoc.similarity(nlp(str(df['DEF2'][i]))))\n",
        "  probIpc2.append(appdoc.similarity(nlp(str(df['DEF2'][i]))))\n",
        "\n",
        "print(\"\\nMAXIMUM VALUES FOR DEF2: \\n\")\n",
        "\n",
        "df['predictionValue2']=pd.Series(probIpc2)\n",
        "print(df.sort_values([\"predictionValue2\"], ascending = False).head(20))\n",
        "print(\"\\n\")\n",
        "\n",
        "#burası çok önemli yeni df'nin indexi sıfırlanmalı\n",
        "df['FULLIPC-Prediction']=df['predictionValue1']+df['predictionValue2']\n",
        "df2 = df.sort_values([\"FULLIPC-Prediction\"], ascending = False)\n",
        "df2 = df2.reset_index(drop=True)\n",
        "print(\"FULL IPC PREDICTION MAX. VALUES:\\n\",df2)\n",
        "\n",
        "# GP-search terms example((side airbag)) ((trim piece)) ((seatback)) before:publication:20140402\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Insert the first meaningful sentence in description regarding ipc: seat vehicle folding lock seats state base rear\n",
            "CHUNK:  lock seats state base rear\n",
            "CHUNK LİSTESİ:  ['lock', 'seats', 'state', 'base', 'rear']\n",
            "MOST FREQ NOUNS:  ['lock', 'seats', 'state', 'base', 'rear']\n",
            "\n",
            "APPDOC:  lock seats state base rear\n",
            "\n",
            "MAXIMUM VALUES FOR DEF1: \n",
            "\n",
            "     IPC  ... predictionValue1\n",
            "13  B60R  ...         0.701618\n",
            "10  B60N  ...         0.697783\n",
            "15  B60T  ...         0.677387\n",
            "0   B60B  ...         0.666240\n",
            "2   B60D  ...         0.645945\n",
            "9   B60M  ...         0.636579\n",
            "16  B60V  ...         0.625198\n",
            "4   B60G  ...         0.616326\n",
            "11  B60P  ...         0.603346\n",
            "17  B60W  ...         0.593467\n",
            "14  B60S  ...         0.568609\n",
            "1   B60C  ...         0.552735\n",
            "7   B60K  ...         0.545255\n",
            "5   B60H  ...         0.542061\n",
            "12  B60Q  ...         0.508696\n",
            "6   B60J  ...         0.469937\n",
            "8   B60L  ...         0.422303\n",
            "3   B60F  ...         0.364296\n",
            "\n",
            "[18 rows x 12 columns]\n",
            "\n",
            "\n",
            "\n",
            "MAXIMUM VALUES FOR DEF2: \n",
            "\n",
            "     IPC  ... predictionValue2\n",
            "0   B60B  ...         0.722455\n",
            "1   B60C  ...         0.722455\n",
            "16  B60V  ...         0.722455\n",
            "15  B60T  ...         0.722455\n",
            "14  B60S  ...         0.722455\n",
            "13  B60R  ...         0.722455\n",
            "12  B60Q  ...         0.722455\n",
            "11  B60P  ...         0.722455\n",
            "10  B60N  ...         0.722455\n",
            "9   B60M  ...         0.722455\n",
            "8   B60L  ...         0.722455\n",
            "7   B60K  ...         0.722455\n",
            "6   B60J  ...         0.722455\n",
            "5   B60H  ...         0.722455\n",
            "4   B60G  ...         0.722455\n",
            "3   B60F  ...         0.722455\n",
            "2   B60D  ...         0.722455\n",
            "17  B60W  ...         0.722455\n",
            "\n",
            "[18 rows x 13 columns]\n",
            "\n",
            "\n",
            "FULL IPC PREDICTION MAX. VALUES:\n",
            "      IPC  ... FULLIPC-Prediction\n",
            "0   B60R  ...           1.424074\n",
            "1   B60N  ...           1.420238\n",
            "2   B60T  ...           1.399842\n",
            "3   B60B  ...           1.388695\n",
            "4   B60D  ...           1.368400\n",
            "5   B60M  ...           1.359034\n",
            "6   B60V  ...           1.347653\n",
            "7   B60G  ...           1.338781\n",
            "8   B60P  ...           1.325802\n",
            "9   B60W  ...           1.315923\n",
            "10  B60S  ...           1.291064\n",
            "11  B60C  ...           1.275190\n",
            "12  B60K  ...           1.267711\n",
            "13  B60H  ...           1.264516\n",
            "14  B60Q  ...           1.231151\n",
            "15  B60J  ...           1.192393\n",
            "16  B60L  ...           1.144759\n",
            "17  B60F  ...           1.086751\n",
            "\n",
            "[18 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ5rnXUnEWYt",
        "colab_type": "code",
        "outputId": "aa6be528-20f2-4b37-d7f5-fb2a2d734f14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df['DEF1']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                      wheel rim castor\n",
              "1                   tyre bead tread band tyre-inflating\n",
              "2            traction coupling hitches draw-gear towing\n",
              "3                                            amphibious\n",
              "4                                            suspension\n",
              "5             heating cooling ventilating air-treatment\n",
              "6             windows windscreens roofs doors coverings\n",
              "7     propulsion transmissions drivetrain fuel-tank ...\n",
              "8              electrically-propelled hybrid-propulsion\n",
              "9     power supply lines electrical-supply trolley-l...\n",
              "10                seats footrests floor-mats turnstiles\n",
              "11    load-transportation fork-lift trucks caravans ...\n",
              "12                          vehicle signalling lighting\n",
              "13    fittings mirrors steps running-boards bumpers ...\n",
              "14    cleaning windscreens wipers jacks vehicle-mano...\n",
              "15                                braking brake-control\n",
              "16                                 air-cushion vehicles\n",
              "17    auto-cruise drive-mode drive-control hybrid-dr...\n",
              "Name: DEF1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2PiPQO6Efyp",
        "colab_type": "code",
        "outputId": "66548094-09a1-43db-bce7-ac4957bf9be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#IPC PREDICT-TOKENS-FULL IPC\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from scipy import spatial\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "my_input = input(\"Insert the first meaningful sentence in description regarding ipc: \")\n",
        "my_input=my_input.lower()\n",
        "\n",
        "#--------\n",
        "input_doc = nlp(my_input)\n",
        "\n",
        "#--------------------\n",
        "#burada token listesi isim ve 'ing' ile biten isimfiilden oluşacak şekilde üretilir\n",
        "\n",
        "token_list=[]\n",
        "for token in input_doc:\n",
        "  if token.pos_== 'NOUN' or token.tag_=='VBG':\n",
        "    if not token.text in ['invention','product','method','system','prior','mechanism','apparatus','device','embodiment','art','state']: \n",
        "      token_list.append(token.text)\n",
        "\n",
        "most_freq_tuple_list = Counter(token_list).most_common(10)\n",
        "print(\"FREKANSLI LİSTE: \\n\",most_freq_tuple_list)\n",
        "most_freq_noun_list = [ word for word,freq in most_freq_tuple_list]\n",
        "print(\"MOST FREQ NOUNS: \", most_freq_noun_list)\n",
        "#--------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "#burada en yüksek frekanslı kelimelerle bir tex oluşturulur ve sonrasında bu doc objesine dönüştürülür\n",
        "ipctext = ' '.join(most_freq_noun_list)\n",
        "\n",
        "appdoc = nlp(ipctext)\n",
        "print(\"\\nAPPDOC: \",appdoc)\n",
        "#---------------------------------------------\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/FULLIPCVEHICLE.tsv', sep='\\t')\n",
        "\n",
        "#BURADA DEF1 SÜTUNU İLE BENZERLİK DEĞERLERİ PROBIPC1 LİSTESİNE EKLENİR. DEF1 4 HANELİ IPC SINIFI İÇİN TANIMDIR\n",
        "probIpc1=[]\n",
        "for i in(range(len(df['IPC']))):\n",
        "  #print(appdoc.similarity(nlp(str(df['DEF1'][i]))))\n",
        "  probIpc1.append(appdoc.similarity(nlp(str(df['DEF1'][i]))))\n",
        "\n",
        "print(\"\\nMAXIMUM VALUES FOR DEF1: \\n\")\n",
        "\n",
        "df['predictionValue1']=pd.Series(probIpc1)\n",
        "print(df.sort_values([\"predictionValue1\"], ascending = False).head(20))\n",
        "print(\"\\n\")\n",
        "\n",
        "#BURADA DEF2 SÜTUNU İLE BENZERLİK DEĞERLERİ PROBIPC2 LİSTESİNE EKLENİR. DEF2 3 HANELİ IPC SINIFI İÇİN TANIMDIR\n",
        "probIpc2=[]\n",
        "for i in(range(len(df['IPC']))):\n",
        "  #print(appdoc.similarity(nlp(str(df['DEF2'][i]))))\n",
        "  probIpc2.append(appdoc.similarity(nlp(str(df['DEF2'][i]))))\n",
        "\n",
        "print(\"\\nMAXIMUM VALUES FOR DEF2: \\n\")\n",
        "\n",
        "df['predictionValue2']=pd.Series(probIpc2)\n",
        "print(df.sort_values([\"predictionValue2\"], ascending = False).head(20))\n",
        "print(\"\\n\")\n",
        "\n",
        "#burası çok önemli yeni df'nin indexi sıfırlanmalı\n",
        "df['FULLIPC-Prediction']=df['predictionValue1']+df['predictionValue2']\n",
        "df2 = df.sort_values([\"FULLIPC-Prediction\"], ascending = False)\n",
        "df2 = df2.reset_index(drop=True)\n",
        "print(\"FULL IPC PREDICTION MAX. VALUES:\\n\",df2)\n",
        "\n",
        "# GP-search terms example:((side airbag)) ((trim piece)) ((seatback)) before:publication:20140402\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Insert the first meaningful sentence in description regarding ipc: echnical Area In particular, the present invention relates to a base lock mechanism for vehicle rear seats. a seat lock folding mechanism that allows hiding. 10 Prior Art The rear seats of the vehicles are designed to increase the luggage space. is provided with a folding mechanism. This mechanism allows If the need to increase the folding of the seats. 15 This mechanism is also used in cases where there is no need to increase the baggage volume. in order to increase the passenger capacity. However, increased safety and comfort if the seat is open in order to lock this mechanism. Thus the vehicle moves the seat is prevented from moving. The lock in question 20 mechanisms are located under the seat and the seat is open locking the vehicle base. However, in the state of the art lock folding mechanisms, weight and cost for folding locks increase. 25 US2005023857 in the state of the art a vehicle seat mechanism is disclosed in the patent document. US2010141004 in the state of the art\n",
            "FREKANSLI LİSTE: \n",
            " [('seat', 6), ('folding', 5), ('lock', 4), ('vehicle', 4), ('seats', 3), ('base', 2), ('need', 2), ('order', 2), ('mechanisms', 2), ('area', 1)]\n",
            "MOST FREQ NOUNS:  ['seat', 'folding', 'lock', 'vehicle', 'seats', 'base', 'need', 'order', 'mechanisms', 'area']\n",
            "\n",
            "APPDOC:  seat folding lock vehicle seats base need order mechanisms area\n",
            "\n",
            "MAXIMUM VALUES FOR DEF1: \n",
            "\n",
            "     IPC  ... predictionValue1\n",
            "13  B60R  ...         0.741207\n",
            "10  B60N  ...         0.702956\n",
            "15  B60T  ...         0.702887\n",
            "2   B60D  ...         0.693660\n",
            "9   B60M  ...         0.690780\n",
            "16  B60V  ...         0.688318\n",
            "11  B60P  ...         0.676688\n",
            "0   B60B  ...         0.674741\n",
            "4   B60G  ...         0.653855\n",
            "14  B60S  ...         0.638407\n",
            "17  B60W  ...         0.638400\n",
            "5   B60H  ...         0.617112\n",
            "12  B60Q  ...         0.595171\n",
            "1   B60C  ...         0.580705\n",
            "7   B60K  ...         0.571512\n",
            "6   B60J  ...         0.493011\n",
            "8   B60L  ...         0.469104\n",
            "3   B60F  ...         0.443460\n",
            "\n",
            "[18 rows x 12 columns]\n",
            "\n",
            "\n",
            "\n",
            "MAXIMUM VALUES FOR DEF2: \n",
            "\n",
            "     IPC  ... predictionValue2\n",
            "0   B60B  ...         0.739794\n",
            "1   B60C  ...         0.739794\n",
            "16  B60V  ...         0.739794\n",
            "15  B60T  ...         0.739794\n",
            "14  B60S  ...         0.739794\n",
            "13  B60R  ...         0.739794\n",
            "12  B60Q  ...         0.739794\n",
            "11  B60P  ...         0.739794\n",
            "10  B60N  ...         0.739794\n",
            "9   B60M  ...         0.739794\n",
            "8   B60L  ...         0.739794\n",
            "7   B60K  ...         0.739794\n",
            "6   B60J  ...         0.739794\n",
            "5   B60H  ...         0.739794\n",
            "4   B60G  ...         0.739794\n",
            "3   B60F  ...         0.739794\n",
            "2   B60D  ...         0.739794\n",
            "17  B60W  ...         0.739794\n",
            "\n",
            "[18 rows x 13 columns]\n",
            "\n",
            "\n",
            "FULL IPC PREDICTION MAX. VALUES:\n",
            "      IPC  ... FULLIPC-Prediction\n",
            "0   B60R  ...           1.481000\n",
            "1   B60N  ...           1.442750\n",
            "2   B60T  ...           1.442680\n",
            "3   B60D  ...           1.433453\n",
            "4   B60M  ...           1.430574\n",
            "5   B60V  ...           1.428111\n",
            "6   B60P  ...           1.416482\n",
            "7   B60B  ...           1.414535\n",
            "8   B60G  ...           1.393649\n",
            "9   B60S  ...           1.378201\n",
            "10  B60W  ...           1.378194\n",
            "11  B60H  ...           1.356906\n",
            "12  B60Q  ...           1.334965\n",
            "13  B60C  ...           1.320499\n",
            "14  B60K  ...           1.311306\n",
            "15  B60J  ...           1.232805\n",
            "16  B60L  ...           1.208898\n",
            "17  B60F  ...           1.183254\n",
            "\n",
            "[18 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}